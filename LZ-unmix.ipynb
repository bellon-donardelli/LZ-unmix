{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01999450",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<center><big><b>LZ-unmix</center></big><br></b>\n",
    "<center><b>Hi!</b> Welcome to <i>LZ-unmix</i>, a python package to separate susceptibility components of distorted magnetic hysteresis!<br></center>\n",
    "<br>\n",
    "<hr>\n",
    "&ensp;<b>1.</b> Before running the cells, make sure all of the extensions are corrected installed in your machine<i> (check the READ_ME_1 file);</i><br>\n",
    "&ensp;<b>2.</b> Make sure your file is included in the same directory holding <i>LZ-unmix</i>;<br>\n",
    "&ensp;<b>3.</b> Individually run each code cell by firstly clicking on a cell and sequentially clicking on the <i>Run</i> button (or press <i> Shift+Enter</i>);<br>\n",
    "&ensp;<b>4.</b> Unless you are an advanced python-user, avoid modifications on the code.<br>\n",
    "&ensp;<b>5.</b> We recommend cleaning the kernel before running a new sample. Go to the Kernel tab and click on <i>\"Restart & Clear Output\"</i>;<br>\n",
    "&ensp;<b>6.</b> Images and csv-files from this package will be saved in the same directory.\n",
    "<hr>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc6f68",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<center><b><big>1. INITIALIZATION</center></b></big>\n",
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c739448",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from LZ_unmix_functions import f1,f2,f3,ferro_area,region_selection,line_inv,moving_mean,gradient,numerical_int,Ms,Mrs\n",
    "from LZ_unmix_functions import LV_whithout_plot1,LV_whithout_plot2,LV_whithout_plot3\n",
    "from LZ_unmix_functions import Levenberg_Marquardt1,Levenberg_Marquardt2,Levenberg_Marquardt3\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f4474f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<center><b><big>2. LOADING THE FILE</center></b></big>\n",
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4123205",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "print('Please, use the button select your file! ')\n",
    "print('Make sure your file has two columns, one for x (field, in Tesla) and other for y (magnetic momentum, Am²), delimited by a comma. ')\n",
    "\n",
    "uploader = widgets.FileUpload()\n",
    "display(uploader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2407b1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<center><b><big>3. FILTERING</center></b></big>\n",
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2618f3",
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file=uploader.metadata[0]['name']\n",
    "sample=input('Name your sample! R: ')\n",
    "grouping = int(input(\"Enter the grouping value for a moving mean filter (must be an integer>1)! R: \"))\n",
    "rows=int(input(\"How many rows should be skipped (must be an integer)? R: \"))\n",
    "\n",
    "x,y=np.loadtxt(file,delimiter=',',unpack=True,skiprows=rows)\n",
    "\n",
    "mass_norm=input('Would you like to normalize by mass?(Y/N) R: ')\n",
    "if mass_norm=='Y':\n",
    "    mass=float(input('Provide the mass (kg) R: '))\n",
    "    y=y/mass\n",
    "    \n",
    "    xnew,ynew=moving_mean(x,grouping),moving_mean(y,grouping)\n",
    "\n",
    "    grad_y=gradient(xnew,ynew)\n",
    "    grad_original=np.copy(grad_y)\n",
    "\n",
    "\n",
    "    factor=max(grad_y)\n",
    "    grad_y=grad_y/factor\n",
    "    figure,(ax1,ax2)=plt.subplots(1,2,figsize=(9,4))\n",
    "\n",
    "    ax1.scatter(x,y,marker='.',c='gray')\n",
    "    ax1.plot(xnew,ynew,marker='.',c='gray',alpha=0.1,label='Smoothing',)\n",
    "    ax1.legend(shadow=True)\n",
    "    ax1.set_xlabel(r'$B \\ (T)$')\n",
    "    ax1.set_ylabel(r'$Magnetic \\  moment \\ (Am²/kg)$')\n",
    "    ax1.grid(alpha=0.5)\n",
    "\n",
    "\n",
    "    ax2.scatter(xnew,grad_y,marker='.',color='gray')\n",
    "    ax2.set_xlabel(r'$B \\ (T)$')\n",
    "    ax2.set_ylabel(r'$\\partial{M}_{(M/Mmax)} / \\partial{B}$')\n",
    "    ax2.grid(alpha=0.5)\n",
    "    figure.tight_layout()\n",
    "\n",
    "    plt.savefig('Smoothing and First Derivative '+str(sample)+'.pdf',dpi=300,facecolor='w')\n",
    "\n",
    "if mass_norm=='N':\n",
    "    y=y\n",
    "    \n",
    "    xnew,ynew=moving_mean(x,grouping),moving_mean(y,grouping)\n",
    "\n",
    "    grad_y=gradient(xnew,ynew)\n",
    "    grad_original=np.copy(grad_y)\n",
    "\n",
    "\n",
    "    factor=max(grad_y)\n",
    "    grad_y=grad_y/factor\n",
    "    figure,(ax1,ax2)=plt.subplots(1,2,figsize=(9,4))\n",
    "\n",
    "    ax1.scatter(x,y,marker='.',c='gray')\n",
    "    ax1.plot(xnew,ynew,marker='.',c='gray',alpha=0.1,label='Smoothing',)\n",
    "    ax1.legend(shadow=True)\n",
    "    ax1.set_xlabel(r'$B \\ (T)$')\n",
    "    ax1.set_ylabel(r'$Magnetic \\  moment \\ (Am²)$')\n",
    "    ax1.grid(alpha=0.5)\n",
    "\n",
    "\n",
    "    ax2.scatter(xnew,grad_y,marker='.',color='gray')\n",
    "    ax2.set_xlabel(r'$B \\ (T)$')\n",
    "    ax2.set_ylabel(r'$\\partial{M}_{(M/Mmax)} / \\partial{B}$')\n",
    "    ax2.grid(alpha=0.5)\n",
    "    figure.tight_layout()\n",
    "\n",
    "    plt.savefig('Smoothing and First Derivative '+str(sample)+'.pdf',dpi=300,facecolor='w')\n",
    "    \n",
    "else:\n",
    "    print('Invalid, please restart the cell!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3202c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<center><b><big>4. DIRECT MODEL</center></b></big>\n",
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934c372d",
   "metadata": {},
   "source": [
    "&ensp;<b>A ↓</b> Estimate the scale of the ferromagnetic contribution (A<sub>t</sub>):\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45af3e3",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "guesses=ferro_area(xnew,grad_y,region_selection,line_inv,numerical_int)\n",
    "print(r'The total (normalized) ferromagnetic area (At) is:',float(np.round(guesses,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb543b0",
   "metadata": {},
   "source": [
    "&ensp;<b>B↓</b> Adjust a direct model with 1, 2 or 3 susceptibility components:\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a5eeb",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def directmodel1(X0=grad_y[0]/20, Bc1=0.001, W1=0.23, A1=guesses[0]):\n",
    "    const1=X0\n",
    "    const2=2/np.pi\n",
    "    Y=np.zeros(np.size(xnew))\n",
    "    for i in range(np.size(Y)):\n",
    "        Y[i]=(const2*((abs(A1)*(abs(W1)/((4*((xnew[i]-abs(Bc1))**2))+(W1**2))))))+const1\n",
    "\n",
    "    figure,(ax1)=plt.subplots(figsize=(5,5))\n",
    "    ax1.plot(xnew,Y,label='Direct model',color='brown')\n",
    "    ax1.scatter(xnew,grad_y,marker='.',label='Data',color='gray',alpha=0.5)\n",
    "    ax1.set_xlabel(r'$B \\ (T)$')\n",
    "    ax1.set_ylabel(r'$\\partial{M} / \\partial{B}_{(M/Mmax)} $')\n",
    "    ax1.set_title(f'{sample}')\n",
    "    ax1.legend(shadow=True)\n",
    "    ax1.grid(alpha=0.5)\n",
    "    figure.tight_layout()\n",
    "    plt.savefig('Direct model '+str(sample)+'.pdf',dpi=300,facecolor='w')\n",
    "    parameters=[X0,Bc1,W1,A1]\n",
    "    return parameters\n",
    "\n",
    "def directmodel2(X0=grad_y[0]/20, Bc1=0.001, W1=0.23, A1=guesses[0], Bc2=0.37, W2=0.2, A2=guesses[0]):\n",
    "    const1=X0\n",
    "    const2=2/np.pi\n",
    "    Y=np.zeros(np.size(xnew))\n",
    "    C1=np.zeros(np.size(xnew))\n",
    "    C2=np.zeros(np.size(xnew))\n",
    "    for i in range(np.size(Y)):\n",
    "        Y[i]=(const2*((abs(A1)*(abs(W1)/((4*((xnew[i]-abs(Bc1))**2))+(W1**2))))+(abs(A2)*(abs(W2)/((4*((xnew[i]-abs(Bc2))**2))+(W2**2))))))+const1\n",
    "        C1[i]=(const2*((abs(A1)*(abs(W1)/((4*((xnew[i]-abs(Bc1))**2))+(W1**2))))))\n",
    "        C2[i]=(const2*((abs(A2)*(abs(W2)/((4*((xnew[i]-abs(Bc2))**2))+(W2**2))))))\n",
    "        \n",
    "    figure,(ax1)=plt.subplots(figsize=(5,5))\n",
    "    ax1.plot(xnew,Y,label='Direct model',color='brown')\n",
    "    ax1.plot(xnew,C1,label=r'$C_{a}$',color='royalblue',linestyle='dashed')\n",
    "    ax1.plot(xnew,C2,label=r'$C_{b}$',color='forestgreen',linestyle='dashed')\n",
    "    ax1.scatter(xnew,grad_y,marker='.',label='Data',color='gray',alpha=0.5)\n",
    "    ax1.set_xlabel(r'$B \\ (T)$')\n",
    "    ax1.set_ylabel(r'$\\partial{M} / \\partial{B}_{(M/Mmax)} $')\n",
    "    ax1.set_title(f'{sample}')\n",
    "    ax1.legend(shadow=True)\n",
    "    ax1.grid(alpha=0.5)\n",
    "    figure.tight_layout()\n",
    "    plt.savefig('Direct model '+str(sample)+'.pdf',dpi=300,facecolor='w')\n",
    "    parameters=[X0,Bc1,W1,A1,Bc2,W2,A2]\n",
    "    return parameters\n",
    "\n",
    "def directmodel3(X0=grad_y[0]/20, Bc1=0.001, W1=0.23, A1=guesses[0], Bc2=0.37, W2=0.2, A2=guesses[0], Bc3=0.6, W3=0.2, A3=guesses[0]):\n",
    "    const1=X0\n",
    "    const2=2/np.pi\n",
    "    Y=np.zeros(np.size(xnew))\n",
    "    C1=np.zeros(np.size(xnew))\n",
    "    C2=np.zeros(np.size(xnew))\n",
    "    C3=np.zeros(np.size(xnew))\n",
    "    for i in range(np.size(Y)):\n",
    "        Y[i]=(const2*((abs(A1)*(abs(W1)/((4*((xnew[i]-abs(Bc1))**2))+(W1**2))))+(abs(A2)*(abs(W2)/((4*((xnew[i]-abs(Bc2))**2))+(W2**2))))+\n",
    "                     (abs(A3)*(abs(W3)/((4*((xnew[i]-abs(Bc3))**2))+(W3**2))))))+const1\n",
    "        \n",
    "        C1[i]=(const2*((abs(A1)*(abs(W1)/((4*((xnew[i]-abs(Bc1))**2))+(W1**2))))))\n",
    "        C2[i]=(const2*((abs(A2)*(abs(W2)/((4*((xnew[i]-abs(Bc2))**2))+(W2**2))))))\n",
    "        C3[i]=(const2*((abs(A3)*(abs(W3)/((4*((xnew[i]-abs(Bc3))**2))+(W3**2))))))\n",
    "        \n",
    "\n",
    "    figure,(ax1)=plt.subplots(figsize=(5,5))\n",
    "    ax1.plot(xnew,Y,label='Direct model',color='brown')\n",
    "    ax1.plot(xnew,C1,label=r'$C_{a}$',color='royalblue',linestyle='dashed')\n",
    "    ax1.plot(xnew,C2,label=r'$C_{b}$',color='forestgreen',linestyle='dashed')\n",
    "    ax1.plot(xnew,C3,label=r'$C_{c}$',color='m',linestyle='dashed')\n",
    "    ax1.scatter(xnew,grad_y,marker='.',label='Data',color='gray',alpha=0.5)\n",
    "    ax1.set_xlabel(r'$B \\ (T)$')\n",
    "    ax1.set_ylabel(r'$\\partial{M} / \\partial{B}_{(M/Mmax)} $')\n",
    "    ax1.set_title(f'{sample}')\n",
    "    ax1.legend(shadow=True)\n",
    "    ax1.grid(alpha=0.5)\n",
    "    figure.tight_layout()\n",
    "    plt.savefig('Direct model '+str(sample)+'.pdf',dpi=300,facecolor='w')\n",
    "    parameters=[X0,Bc1,W1,A1,Bc2,W2,A2,Bc3,W3,A3]\n",
    "    return parameters\n",
    "\n",
    "Choice1=input('Would you like to adjust 1, 2 or 3 components (must be an integer)? R: ')\n",
    "\n",
    "if Choice1=='1':\n",
    "    ajust=directmodel1\n",
    "if Choice1=='2':\n",
    "    ajust=directmodel2\n",
    "if Choice1=='3':\n",
    "    ajust=directmodel3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a=widgets.interactive(ajust,X0=(-1,max(grad_y),abs(grad_y[0]/30)), Bc1=(0,2,0.0001),\n",
    "                 W1=(0,1,0.01), A1=(0,guesses[0]+(2.5*guesses[0]),0.0001),\n",
    "                      Bc2=(0,2,0.0001), W2=(0,1,0.01),A2=(0,guesses[0]+(2.5*guesses[0]),0.0001),\n",
    "                      Bc3=(0,2,0.0001), W3=(0,1,0.01),A3=(0,guesses[0]+(2.5*guesses[0]),0.0001));\n",
    "display(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137de5b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<center><b><big>5. INVERSE MODEL</center></b></big>\n",
    "<hr>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a03e1",
   "metadata": {},
   "source": [
    "&ensp;<b>A ↓</b> Set the initial guesses for optimization <i>(χ<sub>0</sub>,Bc,W,A)</i>:\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08566862",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "constrain=input('Would you like to constrain the solutions assuming that Bc is a constant?(Y/N) R: ')\n",
    "Choice2=input('Would you like to use the parameters adjusted in the direct model as your first guess for the inversion routine(Y/N)? R: ')\n",
    "\n",
    "if Choice1=='1' and (Choice2=='Y' or Choice2=='y' or Choice2=='yes'):\n",
    "    y0_direct=a.kwargs.get('X0')*factor\n",
    "    Bc1_direct=a.kwargs.get('Bc1')\n",
    "    W1_direct=a.kwargs.get('W1')\n",
    "    A1_direct=a.kwargs.get('A1')*factor\n",
    "    \n",
    "if Choice1=='1' and (Choice2=='N' or Choice2=='n' or Choice2=='no'):\n",
    "    print('  ')\n",
    "    print('Provide the inputs for the seven parameters!')\n",
    "    y0_direct=float(input('Provide y0! R: '))\n",
    "    Bc1_direct=float(input('Provide Bc1! R: '))\n",
    "    W1_direct=float(input('Provide W1! R: '))\n",
    "    A1_direct=float(input('Provide A1! R: '))\n",
    "    \n",
    "\n",
    "if Choice1=='2' and (Choice2=='Y' or Choice2=='y' or Choice2=='yes'):\n",
    "    y0_direct=a.kwargs.get('X0')*factor\n",
    "    Bc1_direct=a.kwargs.get('Bc1')\n",
    "    W1_direct=a.kwargs.get('W1')\n",
    "    A1_direct=a.kwargs.get('A1')*factor\n",
    "    Bc2_direct=a.kwargs.get('Bc2')\n",
    "    W2_direct=a.kwargs.get('W2')\n",
    "    A2_direct=a.kwargs.get('A2')*factor\n",
    "    \n",
    "if Choice1=='2' and (Choice2=='N' or Choice2=='n' or Choice2=='no'):\n",
    "    print('  ')\n",
    "    print('Provide the inputs for the seven parameters!')\n",
    "    y0_direct=float(input('Provide y0! R: '))\n",
    "    Bc1_direct=float(input('Provide Bc1! R: '))\n",
    "    W1_direct=float(input('Provide W1! R: '))\n",
    "    A1_direct=float(input('Provide A1! R: '))\n",
    "    Bc2_direct=float(input('Provide Bc2! R: '))\n",
    "    W2_direct=float(input('Provide W2! R: '))\n",
    "    A2_direct=float(input('Provide A2! R: '))\n",
    "    \n",
    "    \n",
    "if Choice1=='3' and (Choice2=='Y' or Choice2=='y' or Choice2=='yes'):\n",
    "    y0_direct=a.kwargs.get('X0')*factor\n",
    "    Bc1_direct=a.kwargs.get('Bc1')\n",
    "    W1_direct=a.kwargs.get('W1')\n",
    "    A1_direct=a.kwargs.get('A1')*factor\n",
    "    Bc2_direct=a.kwargs.get('Bc2')\n",
    "    W2_direct=a.kwargs.get('W2')\n",
    "    A2_direct=a.kwargs.get('A2')*factor\n",
    "    Bc3_direct=a.kwargs.get('Bc3')\n",
    "    W3_direct=a.kwargs.get('W3')\n",
    "    A3_direct=a.kwargs.get('A3')*factor\n",
    "    \n",
    "elif Choice1=='3' and (Choice2=='N' or Choice2=='n' or Choice2=='no'):\n",
    "    print('  ')\n",
    "    print('Provide the inputs for the seven parameters!')\n",
    "    y0_direct=float(input('Provide y0! R: '))\n",
    "    Bc1_direct=float(input('Provide Bc1! R: '))\n",
    "    W1_direct=float(input('Provide W1! R: '))\n",
    "    A1_direct=float(input('Provide A1! R: '))\n",
    "    Bc2_direct=float(input('Provide Bc2! R: '))\n",
    "    W2_direct=float(input('Provide W2! R: '))\n",
    "    A2_direct=float(input('Provide A2! R: '))\n",
    "    Bc3_direct=float(input('Provide x32! R: '))\n",
    "    W3_direct=float(input('Provide W3! R: '))\n",
    "    A3_direct=float(input('Provide A3! R: '))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce18b08",
   "metadata": {},
   "source": [
    "<br>\n",
    "&ensp;<b>B ↓</b> Define your preferences for the inversion routine. Remember, the convergence criteria (ε) might affect convergence, so you might like to run this step more than once if the final adjust is not satisfying. \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Convergence=float(input('What is the criteria (ε) for convergence? Must be a float, default is 1e-5. R: '))\n",
    "Iterations=int(input('What is the limit of iterations (must be an integer)?. R: '))\n",
    "inv=int(input('Define the number of models to be tested (must be an integer)! R: '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31dc79",
   "metadata": {},
   "source": [
    "<br>\n",
    "&ensp;<b>C ↓</b> Create a multidimensional array of initial guesses for optimization, using those set in step <i>5A</i> as the first row of parameters to be inverted, and creating n-others rows with disturbed initial guesses. As the models are sequentially run, <b>this step may take a few seconds</b>.\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0336e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Choice1=='1':\n",
    "    ranged=np.array([y0_direct,Bc1_direct,W1_direct,A1_direct])\n",
    "    variable_guesses=np.zeros((inv,np.size(ranged)))\n",
    "    \n",
    "    if constrain=='Y':\n",
    "        for i in range(inv):\n",
    "            for j in range(np.size(variable_guesses[1])):\n",
    "                if j==0:\n",
    "                    variable_guesses[i,j]=np.array(ranged[j])\n",
    "                else:\n",
    "                    variable_guesses[i,0]=np.array(ranged[0]+np.random.normal(ranged[0],abs(ranged[0]*0.5)))\n",
    "                    variable_guesses[i,1]=np.array(ranged[1])\n",
    "                    variable_guesses[i,2]=np.array(ranged[2]+np.random.normal(ranged[2],abs(ranged[2]*0.5)))\n",
    "                    variable_guesses[i,3]=np.array(ranged[3]+np.random.normal(ranged[3],abs(ranged[3]*0.5)))\n",
    "    if constrain=='N':\n",
    "        for i in range(inv):\n",
    "            for j in range(np.size(variable_guesses[1])):\n",
    "                if j==0:\n",
    "                    variable_guesses[i,j]=np.array(ranged[j])\n",
    "                else:\n",
    "                    variable_guesses[i,0]=np.array(ranged[0]+np.random.normal(ranged[0],abs(ranged[0]*0.5)))\n",
    "                    variable_guesses[i,1]=np.array(ranged[1]+np.random.normal(ranged[0],abs(ranged[0]*0.5)))\n",
    "                    variable_guesses[i,2]=np.array(ranged[2]+np.random.normal(ranged[2],abs(ranged[2]*0.5)))\n",
    "                    variable_guesses[i,3]=np.array(ranged[3]+np.random.normal(ranged[3],abs(ranged[3]*0.5)))\n",
    "\n",
    "\n",
    "    v_inv=np.zeros((len(grad_y),inv))\n",
    "    error_2=np.zeros(inv)\n",
    "    parameterc_ac=np.zeros((len(ranged),inv))\n",
    "    for j in range(inv):\n",
    "        error_2[j],v_inv[:,j],parameterc_ac[:,j]=LV_whithout_plot1(f1,variable_guesses[j,0],variable_guesses[j,1],variable_guesses[j,2],\n",
    "                                                   variable_guesses[j,3],xnew,grad_original,constrain=constrain,condition=1e-8,index=sample,\n",
    "                                                            sx=0.00002);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if Choice1=='2':\n",
    "    ranged=np.array([y0_direct,Bc1_direct,W1_direct,A1_direct,Bc2_direct,W2_direct,A2_direct])\n",
    "    variable_guesses=np.zeros((inv,np.size(ranged)))\n",
    "    if constrain=='Y':\n",
    "        for i in range(inv):\n",
    "            for j in range(np.size(variable_guesses[1])):\n",
    "                if j==0:\n",
    "                    variable_guesses[i,j]=np.array(ranged[j])\n",
    "                else:\n",
    "                    variable_guesses[i,0]=np.array(ranged[0]+np.random.normal(ranged[0],abs(ranged[0])*0.5))\n",
    "                    variable_guesses[i,1]=np.array(ranged[1])\n",
    "                    variable_guesses[i,2]=np.array(ranged[2]+np.random.normal(ranged[2],abs(ranged[2])*0.5))\n",
    "                    variable_guesses[i,3]=np.array(ranged[3]+np.random.normal(ranged[3],abs(ranged[3])*0.5))\n",
    "                    variable_guesses[i,4]=np.array(ranged[4])\n",
    "                    variable_guesses[i,5]=np.array(ranged[5]+np.random.normal(ranged[5],abs(ranged[5])*0.5))\n",
    "                    variable_guesses[i,6]=np.array(ranged[6]+np.random.normal(ranged[6],abs(ranged[6])*0.5))\n",
    "    if constrain=='N':\n",
    "        for i in range(inv):\n",
    "            for j in range(np.size(variable_guesses[1])):\n",
    "                if j==0:\n",
    "                    variable_guesses[i,j]=np.array(ranged[j])\n",
    "                else:\n",
    "                    variable_guesses[i,0]=np.array(ranged[0]+np.random.normal(ranged[0],abs(ranged[0])*0.5))\n",
    "                    variable_guesses[i,1]=np.array(ranged[1]+np.random.normal(ranged[1],abs(ranged[1]*0.5)))\n",
    "                    variable_guesses[i,2]=np.array(ranged[2]+np.random.normal(ranged[2],abs(ranged[2]*0.5)))\n",
    "                    variable_guesses[i,3]=np.array(ranged[3]+np.random.normal(ranged[3],abs(ranged[3]*0.5)))\n",
    "                    variable_guesses[i,4]=np.array(ranged[4]+np.random.normal(ranged[4],abs(ranged[4]*0.5)))\n",
    "                    variable_guesses[i,5]=np.array(ranged[5]+np.random.normal(ranged[5],abs(ranged[5]*0.5)))\n",
    "                    variable_guesses[i,6]=np.array(ranged[6]+np.random.normal(ranged[6],abs(ranged[6]*0.5)))\n",
    "                    \n",
    "    v_inv=np.zeros((len(grad_y),inv))\n",
    "    error_2=np.zeros(inv)\n",
    "    parameterc_ac=np.zeros((len(ranged),inv))\n",
    "\n",
    "    for j in range(inv):\n",
    "        error_2[j],v_inv[:,j],parameterc_ac[:,j]=LV_whithout_plot2(f2,variable_guesses[j,0],variable_guesses[j,1],variable_guesses[j,2],\n",
    "                                                                   variable_guesses[j,3],variable_guesses[j,4],variable_guesses[j,5],\n",
    "                                                                   variable_guesses[j,6],xnew,grad_original,f1,constrain,condition=1e-8,index=sample,sx=0.00002);\n",
    "\n",
    "if Choice1=='3':\n",
    "    ranged=np.array([y0_direct,Bc1_direct,W1_direct,A1_direct,Bc2_direct,W2_direct,A2_direct,Bc3_direct,W3_direct,A3_direct])\n",
    "    variable_guesses=np.zeros((inv,np.size(ranged)))\n",
    "    \n",
    "    if constrain=='Y':\n",
    "        for i in range(inv):\n",
    "            for j in range(np.size(variable_guesses[1])):\n",
    "                if j==0:\n",
    "                    variable_guesses[i,j]=np.array(ranged[j])\n",
    "                else:\n",
    "                    variable_guesses[i,0]=np.array(ranged[0]+np.random.normal(ranged[0],abs(ranged[0])*0.5))\n",
    "                    variable_guesses[i,1]=np.array(ranged[1])\n",
    "                    variable_guesses[i,2]=np.array(ranged[2]+np.random.normal(ranged[2],abs(ranged[2]*0.5)))\n",
    "                    variable_guesses[i,3]=np.array(ranged[3]+np.random.normal(ranged[3],abs(ranged[3]*0.5)))\n",
    "                    variable_guesses[i,4]=np.array(ranged[4])\n",
    "                    variable_guesses[i,5]=np.array(ranged[5]+np.random.normal(ranged[5],abs(ranged[5]*0.5)))\n",
    "                    variable_guesses[i,6]=np.array(ranged[6]+np.random.normal(ranged[6],abs(ranged[6]*0.5)))\n",
    "                    variable_guesses[i,7]=np.array(ranged[7])\n",
    "                    variable_guesses[i,8]=np.array(ranged[8]+np.random.normal(ranged[8],abs(ranged[8]*0.5)))\n",
    "                    variable_guesses[i,9]=np.array(ranged[9]+np.random.normal(ranged[9],abs(ranged[9]*0.5)))\n",
    "                    \n",
    "    if constrain=='N':\n",
    "        for i in range(inv):\n",
    "            for j in range(np.size(variable_guesses[1])):\n",
    "                if j==0:\n",
    "                    variable_guesses[i,j]=np.array(ranged[j])\n",
    "                else:\n",
    "                    variable_guesses[i,0]=np.array(ranged[0]+np.random.normal(ranged[0],abs(ranged[0])*0.5))\n",
    "                    variable_guesses[i,1]=np.array(ranged[1]+np.random.normal(ranged[1],abs(ranged[1])*0.5))\n",
    "                    variable_guesses[i,2]=np.array(ranged[2]+np.random.normal(ranged[2],abs(ranged[2])*0.5))\n",
    "                    variable_guesses[i,3]=np.array(ranged[3]+np.random.normal(ranged[3],abs(ranged[3])*0.5))\n",
    "                    variable_guesses[i,4]=np.array(ranged[4]+np.random.normal(ranged[4],abs(ranged[4])*0.5))\n",
    "                    variable_guesses[i,5]=np.array(ranged[5]+np.random.normal(ranged[5],abs(ranged[5])*0.5))\n",
    "                    variable_guesses[i,6]=np.array(ranged[6]+np.random.normal(ranged[6],abs(ranged[6])*0.5))\n",
    "                    variable_guesses[i,7]=np.array(ranged[7]+np.random.normal(ranged[7],abs(ranged[7])*0.5))\n",
    "                    variable_guesses[i,8]=np.array(ranged[8]+np.random.normal(ranged[8],abs(ranged[8])*0.5))\n",
    "                    variable_guesses[i,9]=np.array(ranged[9]+np.random.normal(ranged[9],abs(ranged[9])*0.5))\n",
    "\n",
    "\n",
    "    v_inv=np.zeros((len(grad_y),inv))\n",
    "    error_2=np.zeros(inv)\n",
    "    parameterc_ac=np.zeros((len(ranged),inv))\n",
    "    for j in range(inv):\n",
    "        error_2[j],v_inv[:,j],parameterc_ac[:,j]=LV_whithout_plot3(f3,variable_guesses[j,0],variable_guesses[j,1],variable_guesses[j,2],\n",
    "                                                   variable_guesses[j,3],variable_guesses[j,4],variable_guesses[j,5],\n",
    "                                                   variable_guesses[j,6],variable_guesses[j,7],variable_guesses[j,8],\n",
    "                                                                  variable_guesses[j,9],xnew,grad_original,f1,constrain,condition=1e-8,index=sample,\n",
    "                                                            sx=0.00002);\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de2de8",
   "metadata": {},
   "source": [
    "<br>\n",
    "&ensp;<b>D ↓</b> Plot the direct models using the optimized parameters obtained in the previous step and shows an hystogram distribution of their euclidian norms <b>‖e‖</b><sub>2</sub>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e697a",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "figure,(ax4,ax5)=plt.subplots(1,2,figsize=(10,5))\n",
    "ax4.plot(xnew,v_inv,alpha=0.2)\n",
    "ax4.scatter(xnew,grad_original,marker='.',color='gray',alpha=0.6,label='Data')\n",
    "ax4.set_xlabel(r'$B \\ (T)$')\n",
    "ax4.set_ylabel(r'$\\partial{M} / \\partial{B}_{(M/Mmax)} $')\n",
    "ax4.legend(shadow=True)\n",
    "ax4.grid(alpha=0.5)\n",
    "ax5=sns.histplot(error_2,kde=True,palette=['royalblue'])\n",
    "ax5.set_xlabel(f'$||e||_{2}$')\n",
    "ax5.set_ylabel('Counts')\n",
    "ax5.grid(alpha=0.5)\n",
    "figure.tight_layout()\n",
    "plt.savefig('Inversion_models '+str(sample)+'.pdf',dpi=300,facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af0d4a",
   "metadata": {},
   "source": [
    "<br>\n",
    "&ensp;<b>E ↓</b> Use the parameters that produced the smallest <b>‖e‖</b><sub>2</sub>value to invert a final model.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f7aed",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "low_error=np.where(error_2==error_2.min())\n",
    "low_error=int(low_error[0])\n",
    "\n",
    "kick=parameterc_ac[:,low_error]\n",
    "\n",
    "if Choice1=='1':\n",
    "    p_lm,bubble_deltad_lm,uncertainty_lm,y_inv=Levenberg_Marquardt1(f1,kick[0],kick[1],kick[2],kick[3],xnew,grad_original,constrain=constrain,\n",
    "                                                                    condition=Convergence,maxiter=Iterations,index=sample,sx=2.0E-5,sy=max(grad_original)*0.05);\n",
    "if Choice1=='2':\n",
    "    p_lm,bubble_deltad_lm,uncertainty_lm,y_inv=Levenberg_Marquardt2(f2,kick[0],kick[1],kick[2],kick[3],\n",
    "                                                             kick[4],kick[5],kick[6],xnew,grad_original,f1,constrain=constrain,\n",
    "                                                             condition=Convergence,maxiter=Iterations,index=sample,sx=2.0E-5,sy=max(grad_original)*0.05);\n",
    "if Choice1=='3':\n",
    "    p_lm,bubble_deltad_lm,uncertainty_lm,y_inv=Levenberg_Marquardt3(f3,kick[0],kick[1],kick[2],kick[3],\n",
    "                                                             kick[4],kick[5],kick[6],kick[7],kick[8],kick[9],xnew,grad_original,f1,constrain=constrain,condition=Convergence,maxiter=Iterations,index=sample,\n",
    "                                                        sx=2.0E-5,sy=max(grad_original)*0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a824a",
   "metadata": {},
   "source": [
    "<br>\n",
    "&ensp;<b>F ↓</b> Apply a simple <b>Two-tailed F-test</b> to verify if the variance of the final model can be distinguished from the variance of the data at 95% of confidence.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c28c7",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "F_stat=np.var(grad_original,ddof=1)/np.var(y_inv,ddof=1)\n",
    "df=np.size(grad_original)-1\n",
    "\n",
    "#find F critical value\n",
    "critical_f=scipy.stats.f.ppf(q=1-(0.05/2), dfn=df, dfd=df)\n",
    "\n",
    "if critical_f>F_stat:\n",
    "    print('Calculated F-value:',F_stat)\n",
    "    print('Critical F-value:',critical_f)\n",
    "    print('The variances of the inversion and the data are indistinguishable  using the two-tailed F-test')\n",
    "if critical_f<F_stat:\n",
    "    print('Calculated F-value:',F_stat)\n",
    "    print('Critical F-value:',critical_f)\n",
    "    print('The variances of the inversion and the data are distinguishable  using the two-tailed F-test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1450180b",
   "metadata": {},
   "source": [
    "<br>\n",
    "&ensp;<b>G ↓</b> Calculate magnetization saturation <b><i>(Ms)</b></i> and magnetization saturation of remanence <i><b>(Mrs)</b></i> through the inverted parameters.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51df0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms_c=[]\n",
    "Mrs_c=[]\n",
    "\n",
    "if Choice1=='1':\n",
    "    Ms_c=Ms(p_lm[3])\n",
    "    Mrs_c=Mrs(p_lm[1],p_lm[2],p_lm[3])\n",
    "    \n",
    "if Choice1=='2':\n",
    "    Ms_c=[Ms(p_lm[3]),Ms(p_lm[6])]\n",
    "    Mrs_c=[Mrs(p_lm[1],p_lm[2],p_lm[3]),Mrs(p_lm[4],p_lm[5],p_lm[6])]\n",
    "    \n",
    "if Choice1=='3':\n",
    "    Ms_c=[Ms(p_lm[3]),Ms(p_lm[6]),Ms(p_lm[9])]\n",
    "    Mrs_c=[Mrs(p_lm[1],p_lm[2],p_lm[3]),Mrs(p_lm[4],p_lm[5],p_lm[6]),Mrs(p_lm[7],p_lm[8],p_lm[9])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727842a",
   "metadata": {},
   "source": [
    "<br>\n",
    "&ensp;<b>H ↓</b> Generate tables to display modeling parameters.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Choice1=='1':\n",
    "    fig1 = go.Figure(data=[go.Table(header=dict(values=['Parameters','Ca']),\n",
    "                     cells=dict(values=[['Bc', 'W', 'A','Ms','Mrs'],\n",
    "                                        [p_lm[1],p_lm[2],p_lm[3],Ms_c,Mrs_c]]))\n",
    "                         ])\n",
    "    fig1.update_layout(width=1000, height=400)\n",
    "    fig1.show()\n",
    "\n",
    "\n",
    "    fig2 = go.Figure(data=[go.Table(header=dict(values=['Parameters','Values']),\n",
    "                     cells=dict(values=[['χ0', 'χferro', '||e||2', 'Calculated F-value','Critical F-value'],\n",
    "                                        [p_lm[0],Ms_c,bubble_deltad_lm,F_stat,critical_f]]))\n",
    "                         ])\n",
    "    fig2.update_layout(width=1000, height=400)\n",
    "    fig2.show()\n",
    "\n",
    "\n",
    "if Choice1=='2':\n",
    "    fig1 = go.Figure(data=[go.Table(header=dict(values=['Parameters','Ca', 'Cb']),\n",
    "                     cells=dict(values=[['Bc', 'W', 'A','Ms','Mrs'],\n",
    "                                        [p_lm[1],p_lm[2],p_lm[3],Ms_c[0],Mrs_c[0]],\n",
    "                                       [p_lm[4],p_lm[5],p_lm[6],Ms_c[1],Mrs_c[1]]]))\n",
    "                         ])\n",
    "    fig1.update_layout(width=1000, height=400)\n",
    "    fig1.show()\n",
    "\n",
    "\n",
    "    fig2 = go.Figure(data=[go.Table(header=dict(values=['Parameters','Values']),\n",
    "                     cells=dict(values=[['χ0', 'χferro', '||e||2', 'Calculated F-value','Critical F-value'],\n",
    "                                        [p_lm[0],Ms_c[0]+Ms_c[1],bubble_deltad_lm,F_stat,critical_f]]))\n",
    "                         ])\n",
    "    fig2.update_layout(width=1000, height=400)\n",
    "    fig2.show()\n",
    "    \n",
    "if Choice1=='3':\n",
    "    fig1 = go.Figure(data=[go.Table(header=dict(values=['Parameters','Ca', 'Cb','Cc']),\n",
    "                     cells=dict(values=[['Bc', 'W', 'A','Ms','Mrs'],\n",
    "                                        [p_lm[1],p_lm[2],p_lm[3],Ms_c[0],Mrs_c[0]],\n",
    "                                       [p_lm[4],p_lm[5],p_lm[6],Ms_c[1],Mrs_c[1]],\n",
    "                                       [p_lm[7],p_lm[8],p_lm[9],Ms_c[2],Mrs_c[2]]]))\n",
    "                         ])\n",
    "    fig1.update_layout(width=1000, height=400)\n",
    "    fig1.show()\n",
    "\n",
    "\n",
    "    fig2 = go.Figure(data=[go.Table(header=dict(values=['Parameters','Values']),\n",
    "                     cells=dict(values=[['χ0', 'χferro', '||e||2', 'Calculated F-value','Critical F-value'],\n",
    "                                        [p_lm[0],Ms_c[0]+Ms_c[1]+Ms_c[2],bubble_deltad_lm,F_stat,critical_f]]))\n",
    "                         ])\n",
    "    fig2.update_layout(width=1000, height=400)\n",
    "    fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924887b",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<hr>\n",
    "<center><b><big> ACKNOWLEDGEMENTS </center></b></big>\n",
    "<hr>\n",
    "<br>\n",
    "<hr>\n",
    "&ensp;We would like to thank the creators and collaborators of the python libraries used in this package:\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<center>&ensp;Numpy <b>[1]</b>, Matplotlib <b>[2]</b>, Scipy <b>[3]</b>, Pandas <b>[4]</b>, Seaborn <b>[5]</b>, Plotly <b>[6]</b></center>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "   \n",
    "&ensp;&ensp;<b>[1]</b> Harris, C.R., and others. Array programming with NumPy. <i>Nature</i> 585, 357–362 (2020). DOI: 10.1038/s41586-020-2649-2.\n",
    "\n",
    "&ensp;&ensp;<b>[2]</b> J. D. Hunter, \"Matplotlib: A 2D Graphics Environment\", <i>Computing in Science & Engineering</i>, vol. 9, no. 3, pp. 90-95, 2007. DOI: 10.5281/zenodo.592536.\n",
    "\n",
    "&ensp;&ensp;<b>[3]</b> Virtanen, P., and others (2020) SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. <i>Nature Methods</i>, 17(3), 261-272. DOI: 10.1038/s41592-019-0686-2.\n",
    "\n",
    "&ensp;&ensp;<b>[4]</b> McKinney, W., and others. (2010). Data structures for statistical computing in python. In: <i>Proceedings of the 9th Python in Science Conference</i> (Vol. 445, pp. 51–56).\n",
    "\n",
    "&ensp;&ensp;<b>[5]</b> Waskom, M., and others (2017). mwaskom/seaborn: v0.8.1 (September 2017). Zenodo. DOI: 10.5281/zenodo.883859\n",
    "\n",
    "&ensp;&ensp;<b>[6]</b> Inc., P. T. (2015). Collaborative data science. Montreal, QC: Plotly Technologies Inc. Retrieved from https://plot.ly.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258fea3a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d04bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
